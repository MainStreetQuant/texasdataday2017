{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Similarity Measures II: KB + Syn-Sem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Contents\n",
    "\n",
    "* I. Corpora (SpaCy Preprocessing for Lemmatization)\n",
    "    * MSR Paraphrase Corpus (for evaluation)\n",
    "    * Brown Corpus (for computing info content of words)\n",
    "    * WordNet (for computing word similarity)\n",
    "* II. Word Similarity\n",
    "* III. Sentence Similarity\n",
    "* IV. Word-Order Similarity\n",
    "* V. Overall Sentence Similarity (Linear Combination of Sent & Word Similarities)\n",
    "* VI. Evaluation (Not Using MSR for now, computationally expensive)\n",
    "\n",
    "* VII. Extension (SRL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MSR Paraphrase Corpus\n",
    "* NLTK WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. MSR Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/CORPORA/paraphrase/msr_paraphrase_train.txt\"\n",
    "test_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/CORPORA/paraphrase/msr_paraphrase_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>#1 ID</th>\n",
       "      <th>#2 ID</th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>702876</td>\n",
       "      <td>702977</td>\n",
       "      <td>Amrozi accused his brother, whom he called the...</td>\n",
       "      <td>Referring to him as only the witness, Amrozi a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2108705</td>\n",
       "      <td>2108831</td>\n",
       "      <td>Yucaipa owned Dominick's before selling the ch...</td>\n",
       "      <td>Yucaipa bought Dominick's in 1995 for $693 mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1330381</td>\n",
       "      <td>1330521</td>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10, the ship's owners had published an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3344667</td>\n",
       "      <td>3344648</td>\n",
       "      <td>Around 0335 GMT, Tab shares were up 19 cents, ...</td>\n",
       "      <td>Tab shares jumped 20 cents, or 4.6%, to set a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1236820</td>\n",
       "      <td>1236712</td>\n",
       "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
       "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quality    #1 ID    #2 ID  \\\n",
       "0        1   702876   702977   \n",
       "1        0  2108705  2108831   \n",
       "2        1  1330381  1330521   \n",
       "3        0  3344667  3344648   \n",
       "4        1  1236820  1236712   \n",
       "\n",
       "                                           #1 String  \\\n",
       "0  Amrozi accused his brother, whom he called the...   \n",
       "1  Yucaipa owned Dominick's before selling the ch...   \n",
       "2  They had published an advertisement on the Int...   \n",
       "3  Around 0335 GMT, Tab shares were up 19 cents, ...   \n",
       "4  The stock rose $2.11, or about 11 percent, to ...   \n",
       "\n",
       "                                           #2 String  \n",
       "0  Referring to him as only the witness, Amrozi a...  \n",
       "1  Yucaipa bought Dominick's in 1995 for $693 mil...  \n",
       "2  On June 10, the ship's owners had published an...  \n",
       "3  Tab shares jumped 20 cents, or 4.6%, to set a ...  \n",
       "4  PG&E Corp. shares jumped $1.63 or 8 percent to...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_table(train_path, encoding='utf-8-sig')\n",
    "df_test = pd.read_table(test_path, encoding='utf-8-sig')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4076, 5)\n",
      "(1725, 5)\n"
     ]
    }
   ],
   "source": [
    "print df_train.shape\n",
    "print df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quality                                                      1\n",
       "#1 ID                                                   702876\n",
       "#2 ID                                                   702977\n",
       "#1 String    Amrozi accused his brother, whom he called the...\n",
       "#2 String    Referring to him as only the witness, Amrozi a...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.ix[0] # NB: index Quality is actually weirdly '﻿Quality', using '."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Amrozi accused his brother, whom he called the witness, of deliberately distorting his evidence.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.ix[0]['#1 String']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_msr(df, indexer):\n",
    "    \n",
    "    X_dic, Y_dic = defaultdict(lambda x: defaultdict(list)), \\\n",
    "                   defaultdict(lambda x: defaultdict(list))\n",
    "    \n",
    "    for i in indexer:\n",
    "        \n",
    "        entry_dic = defaultdict(list)\n",
    "        s1, s2 = df.ix[i]['#1 String'][:-1], \\\n",
    "                 df.ix[i]['#2 String'][:-1] \n",
    "                # get rid of period, which causes problem in distinguishing identical tokens.\n",
    "        \n",
    "        parsed_s1, parsed_s2 = parser(unicode(s1)), parser(unicode(s2))\n",
    "        \n",
    "        entry_dic['s1'] = [token.orth_ for token in parsed_s1]\n",
    "        entry_dic['s2'] = [token.orth_ for token in parsed_s2]\n",
    "        entry_dic['s1_lm'] = [token.lemma_ for token in parsed_s1]\n",
    "        entry_dic['s2_lm'] = [token.lemma_ for token in parsed_s2] \n",
    "#         parsed_lm_s1, parsed_lm_s2 = parser(' '.join(entry_dic['s1_lm'])), \\\n",
    "#                                     parser(' '.join(entry_dic['s2_lm'])) # parse on lemmas.\n",
    "        \n",
    "#         entry_dic['s1_dep_lm'] = dep_lemmas(parsed_lm_s1) # for dep lemma features.\n",
    "#         entry_dic['s2_dep_lm'] = dep_lemmas(parsed_lm_s2)\n",
    "#         entry_dic['s1_dep_tk'] = dep_tokens(parsed_s1) # for dep token features.\n",
    "#         entry_dic['s2_dep_tk'] = dep_tokens(parsed_s2) \n",
    "#         entry_dic['s1_root_lm'] = get_root(parsed_lm_s1)\n",
    "#         entry_dic['s2_root_lm'] = get_root(parsed_lm_s2)\n",
    "#         entry_dic['s1_root_tk'] = get_root(parsed_s1)\n",
    "#         entry_dic['s2_root_tk'] = get_root(parsed_s2)\n",
    "\n",
    "        entry_dic['s1_id'] = df.ix[i]['#1 ID'] # for error analysis later.\n",
    "        entry_dic['s2_id'] = df.ix[i]['#2 ID']\n",
    "        X_dic[i] = entry_dic\n",
    "        Y_dic[i] = df.ix[i]['Quality']\n",
    "    \n",
    "    return X_dic, Y_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.3 s, sys: 161 ms, total: 18.5 s\n",
      "Wall time: 18.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, Y_train = parse_msr(df_train, df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.37 s, sys: 57.3 ms, total: 7.42 s\n",
      "Wall time: 7.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test, Y_test = parse_msr(df_test, df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# msr_sents, msr_words = parse_msr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print msr_sents[0]\n",
    "# print\n",
    "# print msr_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Brown Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_brown():\n",
    "    \n",
    "    sents = brown.sents()\n",
    "    parsed_sents = [parser(' '.join(sent)) for sent in sents]\n",
    "    lemma_words = [token.lemma_ for parsed_sent in parsed_sents for token in parsed_sent]\n",
    "    \n",
    "    return lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 44s, sys: 830 ms, total: 1min 44s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "brown_words = parse_brown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188973"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(brown_words)\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Word Similarity with Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* **Li et al. (2006)'s WordNet Word Similarity**\n",
    "    * Equation: $SIM(w_1,w_2) = e^{-\\alpha l}\\cdot \\frac{e^{\\beta h}-e^{-\\beta h}}{e^{\\beta h}+e^{-\\beta h}}$ (cf. ibid.:14,(5)).\n",
    "    * Breakdown: The similarity between $w_1$ and $w_2$ is the product of the following functions:\n",
    "        * Path Length Function: $f(l) = e^{-\\alpha l}$\n",
    "        * Subsumer Depth Function: $g(h) = \\frac{e^{\\beta h}-e^{-\\beta h}}{e^{\\beta h}+e^{-\\beta h}}$\n",
    "    * Measures:\n",
    "        * Path Length: (cf. ibid.:13)\n",
    "            * $0$ if $w_1$ and $w_2$ are in the same synset.\n",
    "            * $1$ if $w_1$ and $w_2$ are not in the same synset but the synset for $w_1$ and $w_2$ contain one or more common words.\n",
    "            * *shortest path length* according to WordNet if neither of the above is true.\n",
    "        * Subsumer Depth: (cf. ibid.:14)\n",
    "            * \"Words at upper layers of hierarchical semantic nets have more general concepts and less semantic similarity between words than words at lower layers. Therefore $g(h)$ should increase monotonically with respect to the subsumer depth\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmas = lambda synset: frozenset(str(lemma.name()) for lemma in synset.lemmas()\n",
    "                         if '_' not in str(lemma.name())) # there are lemmas like 'domestic_dog'.\n",
    "div = lambda x,y: x/y if y!=0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PATH_LEN_CACHE = {}\n",
    "def path_len(w1, w2):\n",
    "    \n",
    "    if (w1,w2) in PATH_LEN_CACHE: \n",
    "        return PATH_LEN_CACHE[(w1,w2)]\n",
    "        \n",
    "    w1synsets, w2synsets = wn.synsets(w1), wn.synsets(w2)\n",
    "    w1syns = {lemmas(syn) for syn in w1synsets}\n",
    "    w2syns = {lemmas(syn) for syn in w2synsets}\n",
    "    \n",
    "    for syn in w1syns.union(w2syns):\n",
    "        if w1 in syn and w2 in syn:\n",
    "            return 0\n",
    "    for w1syn in w1syns:\n",
    "        for w2syn in w2syns:\n",
    "            if w1syn.intersection(w2syn):\n",
    "                return 1\n",
    "    pls = []\n",
    "    for w1syn in w1synsets:\n",
    "        for w2syn in w2synsets:\n",
    "            pl = w1syn.shortest_path_distance(w2syn)\n",
    "            if pl!=None: pls.append(pl)\n",
    "    \n",
    "    PATH_LEN_CACHE[(w1,w2)] = 50 if len(pls)==0 else min(pls)\n",
    "    \n",
    "    return PATH_LEN_CACHE[(w1,w2)] # to penalize non-related words\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 2 µs, total: 7 µs\n",
      "Wall time: 10 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "path_len('dog','cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUBSUMER_CACHE = {}\n",
    "def subsumer_depth(w1, w2):\n",
    "    \n",
    "    if (w1,w2) in SUBSUMER_CACHE: \n",
    "        return SUBSUMER_CACHE[(w1,w2)]    \n",
    "    \n",
    "    w1synsets, w2synsets = wn.synsets(w1), wn.synsets(w2)\n",
    "    subsumers = []\n",
    "    for w1syn in w1synsets:\n",
    "        for w2syn in w2synsets:\n",
    "            subsumers += w1syn.common_hypernyms(w2syn)\n",
    "    subsumers = list(set(subsumers))\n",
    "    \n",
    "    depths = [subsumer.min_depth() for subsumer in subsumers] \n",
    "    \n",
    "    SUBSUMER_CACHE[(w1,w2)] = 0 if len(depths)==0 else max(depths) # penalizes no-subsumer case.\n",
    "    \n",
    "    return SUBSUMER_CACHE[(w1,w2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "subsumer_depth('dog','cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD_SIM_CACHE = {}\n",
    "def word_sim(w1, w2, alpha=.2, beta=.45):\n",
    "    \n",
    "    if (w1,w2) in WORD_SIM_CACHE:\n",
    "        return WORD_SIM_CACHE[(w1,w2)]\n",
    "    \n",
    "    l, h = path_len(w1,w2), subsumer_depth(w1,w2)\n",
    "    \n",
    "    WORD_SIM_CACHE[(w1,w2)] = np.exp(-alpha*l) * \\\n",
    "                              div(np.exp(beta*h)-np.exp(-beta*h), \\\n",
    "                              np.exp(beta*h)+np.exp(-beta*h))\n",
    "        \n",
    "    return WORD_SIM_CACHE[(w1,w2)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.449283876504\n",
      "0.818697350358\n",
      "CPU times: user 124 µs, sys: 26 µs, total: 150 µs\n",
      "Wall time: 138 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print word_sim('dog','cat')\n",
    "print word_sim('dog','canine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Sentence Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* **Sentence Vector $\\check{s}$**:\n",
    "    * Build a vector template $\\check{s}$ the cells of which correspond to the set of distinctive words in two sentences $s_1$, $s_2$, i.e. $\\{w|w\\in s_1\\cup s_2\\}$.\n",
    "    * For $s_1$ and $s_1$, build their vector $\\check{s}_1$ and $\\check{s}_2$ as follows: for each $w$ in $\\check{s}$,\n",
    "        * If $w$ appears in a sentence, set $\\check{s}_{1/2,i} = 1$\n",
    "        * Otherwise, compute $w$'s similarities to all the words in $\\check{s}_{1/2}$, and set $\\check{s}_{1/2,i}$ to be the highest similarity value resulted.\n",
    "    * Each cell of $\\check{s}_{1/2,i}$ is weighted by the corresponding word $w_i$'s *Information Content*, which is computed with $I(w) = \\frac{logp(w)}{log(N+1)} = 1 - \\frac{log(n+1)}{log(N+1)}$, where $n$ is the frequence of $w$ in a corpus (Brown, in this case), $N$ is the size of the corpus. The normalization: $\\check{s}_i = \\check{s}_i\\cdot I(w_i)\\cdot I(\\tilde{w}_i)$, where $\\tilde{w}_i$ is the word entry that is associated with $w_i$ (i.e. either itself, when $w$ is found in a sentence, and $w$'s most similar word otherwise). \n",
    "\n",
    "\n",
    "* **Sentence Similarity**:\n",
    "    * Equation: $SIM(s_1,s_2) = \\frac{\\check{s}_1\\cdot\\check{s}_2}{||\\check{s}_1||\\cdot||\\check{s}_2||}$.\n",
    "    * I.e. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = lambda x: np.log(x) if x>0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I_CACHE = {}\n",
    "def I(w):\n",
    "    if w in I_CACHE:\n",
    "        return I_CACHE[w]\n",
    "    else:\n",
    "        I_CACHE[w] = 1 - div(log(brown_words.count(w)+1),log(N+1))\n",
    "    return I_CACHE[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vec(s1, s2): # assuming s1,s2 are lists of words.\n",
    "    \n",
    "    s_check = list(set(s1).union(set(s2)))\n",
    "    l_check = len(s_check)\n",
    "    s1_check, s2_check = np.zeros(l_check), np.zeros(l_check)\n",
    "    for i,w in enumerate(s_check):\n",
    "        if w in s1: s1_check[i] = 1\n",
    "        else: \n",
    "            idx,most_sim = max(enumerate(s1), key=lambda (j,w_j):word_sim(w,w_j)) # idx: that of w's most sim.\n",
    "            s1_check[i] = word_sim(w,most_sim) * I(w) * I(s1[idx]) # weight by info content\n",
    "        if w in s2: s2_check[i] = 1\n",
    "        else: \n",
    "            idx,most_sim = max(enumerate(s2), key=lambda (j,w_j):word_sim(w,w_j)) \n",
    "            s2_check[i] = word_sim(w,most_sim) * I(w) * I(s2[idx])\n",
    "    \n",
    "    return s1_check, s2_check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent_sim(s1, s2):\n",
    "    \n",
    "    s1_vec, s2_vec = vec(s1, s2)\n",
    "    \n",
    "    return div(np.dot(s1_vec,s2_vec),\n",
    "               np.sqrt(np.dot(s1_vec,s1_vec)) * \\\n",
    "               np.sqrt(np.dot(s2_vec,s2_vec)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = X_train[0]['s1']\n",
    "r1 = X_train[0]['s2'] # known to be the paraphrase pairmate to q.\n",
    "r2 = X_train[1]['s1'] # know to be not the paraphrase pairmate to q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805565926878\n",
      "0.150437483504\n",
      "CPU times: user 5.22 ms, sys: 1.34 ms, total: 6.56 ms\n",
      "Wall time: 5.66 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print sent_sim(q, r1)\n",
    "print sent_sim(q, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Amrozi', u'accused', u'his', u'brother', u',', u'whom', u'he', u'called', u'the', u'witness', u',', u'of', u'deliberately', u'distorting', u'his', u'evidence']\n"
     ]
    }
   ],
   "source": [
    "print q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Word-Order Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* **Order Similarity**:\n",
    "    * Equation: $SIM(s_1,s_2) = 1 - \\frac{||r_1 - r_2||}{||r_1 + r_2||}$ (cf. Li et al. (2006):18,(8)).\n",
    "    * Breakdown: Word order vectors $r_1$ and $r_2$ are computed as follows:\n",
    "        * Build vector template $\\check{s}$ as in section III.\n",
    "        * For $s_1$ and $s_2$, build word order vectors. For each $w$ in $\\check{s}$,\n",
    "            * If $w$ is found in $s_{1/2}$, set $r_{1/2,i}$ to be 1.\n",
    "            * Otherwise, set $r_{1/2,i}$ to be the index of the $w$'s most similar word in $s_{1/2}$.\n",
    "    * Idea: \"... normalized difference of word order\" (cf. ibid.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def order_vec(s1, s2):\n",
    "    \n",
    "    s_check = list(set(s1).union(set(s2)))\n",
    "    l_check = len(s_check)\n",
    "    r1, r2 = np.zeros(l_check), np.zeros(l_check)    \n",
    "    for i,w in enumerate(s_check):\n",
    "        if w in s1:\n",
    "            r1[i] = s1.index(w)\n",
    "        else:\n",
    "            most_sim = max(s1, key=lambda w_j:word_sim(w,w_j)) \n",
    "            r1[i] = s1.index(most_sim)\n",
    "        if w in s2:\n",
    "            r2[i] = s2.index(w)\n",
    "        else:\n",
    "            most_sim = max(s2, key=lambda w_j:word_sim(w,w_j)) \n",
    "            r2[i] = s2.index(most_sim)   \n",
    "            \n",
    "    return r1, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def order_sim(s1, s2):\n",
    "    \n",
    "    r1, r2 = order_vec(s1, s2)\n",
    "    \n",
    "    diff = r1 - r2\n",
    "    norm = r1 + r2\n",
    "    \n",
    "    return 1 - div(np.sqrt(np.dot(diff,diff)),np.sqrt(np.dot(norm,norm)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671823693459\n",
      "0.406778405642\n",
      "CPU times: user 1.08 ms, sys: 452 µs, total: 1.53 ms\n",
      "Wall time: 1.19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print order_sim(q,r1)\n",
    "print order_sim(q,r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Overall Sentence Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $SIM(s_1,s_2) = \\delta\\cdot SIM_{sent}(s_1,s_2) + (1-\\delta)\\cdot SIM_{order}(s_1,s_2)$.\n",
    "* $\\delta \\in (0.5,1]$, considering word order's \"... subordinate role in semantic processing\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overall_sent_sim(s1, s2, delta=.85): # delta is a value between [.5,1]. (cf. Li et al. (2006):20,24)\n",
    "    \n",
    "    return delta*sent_sim(s1,s2) + (1-delta)*order_sim(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785504591865\n",
      "0.188888621825\n",
      "CPU times: user 2.09 ms, sys: 1.17 ms, total: 3.26 ms\n",
      "Wall time: 2.55 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print overall_sent_sim(q,r1)\n",
    "print overall_sent_sim(q,r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Li et al. (2006) + Wan et al. (2006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(X_test_fts, Y_test_fts, model):\n",
    "    y_true = Y_test_fts\n",
    "    y_pred = model.predict(X_test_fts)\n",
    "    print 'Accuracy: %.6f' % accuracy_score(y_true,y_pred)\n",
    "    print\n",
    "    print classification_report(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Wan et al. (2006): Featurized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Amrozi', u'accused', u'his', u'brother', u',', u'whom', u'he', u'called', u'the', u'witness', u',', u'of', u'deliberately', u'distorting', u'his', u'evidence']\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print X_train[0]['s1']; print\n",
    "print Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD W06 FEATURES\n",
    "# with open(data_path+'train1.p','rb') as f_train:\n",
    "#     X_train_w06fts, Y_train_w06fts = cPickle.load(f_train)\n",
    "# with open(data_path+'test1.p','rb') as f_test:\n",
    "#     X_test_w06fts, Y_test_w06fts = cPickle.load(f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36.129483428692055, 34.004219697592525, 35.034650597519565, 50.932376695342796, 47.936354536793218, 49.388971340938468, 0.5, 0.4924790605054523, 0.49621103366618263, 0.5, 0.4924790605054523, 0.49621103366618263, 0.5714285714285714, 0.5, 0.5333333333333333, 0.5714285714285714, 0.5, 0.5333333333333333, 13, 13, -1, 1]\n"
     ]
    }
   ],
   "source": [
    "print X_train_w06fts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does Li et al. (2006) do on MSR on its own?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize(X_train, Y_train, X_test, Y_test, sim):\n",
    "    \n",
    "    X_train_fts, Y_train_fts = [], []\n",
    "    X_test_fts, Y_test_fts = [], []\n",
    "    \n",
    "    print \"... processing train\"\n",
    "    for i,x in X_train.iteritems():\n",
    "        if i!=0 and i%100==0:\n",
    "            print \"    ... processed %d train sentences\" % i\n",
    "        X_train_fts.append(sim(x['s1_lm'],x['s2_lm']))\n",
    "        Y_train_fts.append(Y_train[i])\n",
    "    print \"... processing test\"\n",
    "    for i,x in X_test.iteritems():\n",
    "        if i!=0 and i%100==0:\n",
    "            print \"    ... processed %d test sentences\" % i\n",
    "        X_test_fts.append(sim(x['s1_lm'],x['s2_lm']))\n",
    "        Y_test_fts.append(Y_test[i])  \n",
    "        \n",
    "    return X_train_fts, Y_train_fts, X_test_fts, Y_test_fts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_fts, Y_train_fts, X_test_fts, Y_test_fts = featurize(X_train, Y_train, X_test, Y_test, overall_sent_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CONVERT TO LISTS OF LISTS\n",
    "X_train_fts = [[ft] for ft in X_train_fts]\n",
    "X_test_fts = [[ft] for ft in X_test_fts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAVE\n",
    "# with open(data_path+'li2006_fts.p','wb') as f:\n",
    "#     cPickle.dump((X_train_fts,Y_train_fts,X_test_fts,Y_test_fts), f)\n",
    "# LOAD\n",
    "# with open(data_path+'li2006_fts.p','rb') as f:\n",
    "#     X_train_fts,Y_train_fts,X_test_fts,Y_test_fts = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_li = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_li.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.731845\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.38      0.48      1323\n",
      "          1       0.75      0.90      0.82      2753\n",
      "\n",
      "avg / total       0.72      0.73      0.71      4076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_train_fts, Y_train_fts, lr_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.732174\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.41      0.51       578\n",
      "          1       0.75      0.90      0.82      1147\n",
      "\n",
      "avg / total       0.72      0.73      0.71      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_test_fts, Y_test_fts, lr_li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does Wan et al. (2006) do on MSR on its own?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_wan = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_wan.fit(X_train_w06fts, Y_train_w06fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.736997\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.48      0.54      1323\n",
      "          1       0.78      0.86      0.82      2753\n",
      "\n",
      "avg / total       0.73      0.74      0.73      4076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_train_w06fts, Y_train_w06fts, lr_wan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.732754\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.51      0.56       578\n",
      "          1       0.77      0.85      0.81      1147\n",
      "\n",
      "avg / total       0.72      0.73      0.73      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_test_w06fts, Y_test_w06fts, lr_wan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wan + Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize_plus(wan_fts, li_fts):\n",
    "    \n",
    "    X_train_wan, Y_train_wan, X_test_wan, Y_test_wan = wan_fts\n",
    "    X_train_li, Y_train_li, X_test_li, Y_test_li = li_fts\n",
    "    \n",
    "    X_train_fts, Y_train_fts = [], []\n",
    "    X_test_fts, Y_test_fts = [], []\n",
    "    \n",
    "    for i,(x_wan,x_li) in enumerate(zip(X_train_wan,X_train_li)):\n",
    "        X_train_fts.append(x_wan+x_li) \n",
    "        Y_train_fts.append(Y_train_li[i])\n",
    "    for i,(x_wan,x_li) in enumerate(zip(X_test_wan,X_test_li)):\n",
    "        X_test_fts.append(x_wan+x_li)\n",
    "        Y_test_fts.append(Y_test_li[i])\n",
    "        \n",
    "    return X_train_fts, Y_train_fts, X_test_fts, Y_test_fts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wan_fts = (X_train_w06fts,Y_train_w06fts,X_test_w06fts,Y_test_w06fts)\n",
    "li_fts = (X_train_fts,Y_train_fts,X_test_fts,Y_test_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.84 ms, sys: 1.66 ms, total: 10.5 ms\n",
      "Wall time: 9.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_fts, Y_train_fts, X_test_fts, Y_test_fts = featurize_plus(wan_fts,li_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_wan_li = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_wan_li.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.736997\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.48      0.54      1323\n",
      "          1       0.78      0.86      0.82      2753\n",
      "\n",
      "avg / total       0.73      0.74      0.73      4076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_train_w06fts, Y_train_w06fts, lr_wan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.731594\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.50      0.55       578\n",
      "          1       0.77      0.85      0.81      1147\n",
      "\n",
      "avg / total       0.72      0.73      0.72      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_test_fts, Y_test_fts, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_linear = svm.SVC(kernel='linear',verbose=3)\n",
    "svm_rbf = svm.SVC(kernel='rbf',verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_linsvc = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]CPU times: user 12.5 s, sys: 67.9 ms, total: 12.6 s\n",
      "Wall time: 12.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=3)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_linear.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.746075\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.46      0.54      1323\n",
      "          1       0.77      0.88      0.82      2753\n",
      "\n",
      "avg / total       0.73      0.75      0.73      4076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_train_fts, Y_train_fts, svm_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.734493\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.47      0.54       578\n",
      "          1       0.77      0.87      0.81      1147\n",
      "\n",
      "avg / total       0.72      0.73      0.72      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_test_fts, Y_test_fts, svm_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]CPU times: user 1.15 s, sys: 7.2 ms, total: 1.15 s\n",
      "Wall time: 1.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=3)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_rbf.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.940137\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.86      0.90      1323\n",
      "          1       0.94      0.98      0.96      2753\n",
      "\n",
      "avg / total       0.94      0.94      0.94      4076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_train_fts, Y_train_fts, svm_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.692754\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.30      0.39       578\n",
      "          1       0.72      0.89      0.79      1147\n",
      "\n",
      "avg / total       0.67      0.69      0.66      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_test_fts, Y_test_fts, svm_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 398 ms, sys: 2.02 ms, total: 400 ms\n",
      "Wall time: 401 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_linsvc.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.525025\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.96      0.57      1323\n",
      "          1       0.94      0.32      0.47      2753\n",
      "\n",
      "avg / total       0.77      0.53      0.50      4076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_train_fts, Y_train_fts, svm_linsvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.509565\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.94      0.56       578\n",
      "          1       0.91      0.29      0.44      1147\n",
      "\n",
      "avg / total       0.74      0.51      0.48      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_test_fts, Y_test_fts, svm_linsvc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. OJO Sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ojo_sents = '''\n",
    "What are the quality of schools in this neighborhood?\n",
    "What areas have the best schools?\n",
    "What are the crime statistics in this neighborhood?\n",
    "What are the number of registered sex offenders in this neighborhood?\n",
    "What is the walkability score in this neighborhood?\n",
    "Which neighborhoods have homes that are over 2500 sq ft. \n",
    "What neighborhoods have new construction?\n",
    "Show me pictures of the neighborhood\n",
    "Show me pictures of homes in the neighborhood\n",
    "How bicycle friendly is this neighborhood?\n",
    "What is the median income of this neighborhood?\n",
    "What is the average demographics of this neighborhood? \n",
    "What is the poverty score of this neighborhood?\n",
    "What is the best day of the week to list my home?\n",
    "What is the best month to list a home like mine for the most money and shortest time?\n",
    "How much has my home appreciated?\n",
    "How has appreciation been in my neighborhood vs other neighborhoods?\n",
    "What has the average appreciation in my neighborhood been over the last x years?\n",
    "What has the average appreciation in my school district been over the last x years?\n",
    "What has the average appreciation on my street been over the last x years?\n",
    "Which neighborhoods are best for kids under 10\n",
    "Show me the nearest parks\n",
    "Show me the nearest pools\n",
    "Show me the nearest dog parks\n",
    "Show me the nearest urgent care / emergency room?\n",
    "Show me the nearest fire / police station?\n",
    "Show me the impact of railroad/trains\n",
    "How has appreciation been in this neighborhood vs other neighborhoods?\n",
    "What has the average appreciation in this neighborhood over the last x years?\n",
    "What has the average appreciation in this school district over the last x years?\n",
    "Where can I find a house that is a better fit for me for less money?\n",
    "What is the commute time for this neighborhood?\n",
    "Which neighborhoods have a commute time of less than 30min from [address]\n",
    "I want to live in a low traffic spot\n",
    "Show me diversity of neighborhood\n",
    "Show me historic natural disaster trends for this area\n",
    "Show me historic weather trends for this area\n",
    "Where can I find a house that is a better fit for me for less money?\n",
    "What confidence level does OJO have that I should list my home now?\n",
    "What confidence level does OJO have that I should buy a home right now?\n",
    "How much is my home worth?\n",
    "What confidence level does OJO have that I should buy a home right now?\n",
    "Show me district city government information\n",
    "Which street(s) in this neighborhood have the highest appreciation over x years?\n",
    "What is the expected appreciation for my home over the next x years?\n",
    "Which neighborhood in Austin is expected to appreciate the most over the next x years that have homes similar to what I'm interested in?\n",
    "What areas have mature trees?\n",
    "What areas have the most greenspace?\n",
    "What is the expected appreciation for homes in this area over the next x years?\n",
    "How is this neighborhood impacted by traffic congestion and which time(s) of day?\n",
    "How fast will my home sell?\n",
    "Is this a pet friendly neighborhood?\n",
    "What are the utility costs in this neighborhood?\n",
    "I want to live in a tidy area\n",
    "I want a area where the homes are setback from the streeet\n",
    "Are there complete streets in this neighborhood (connecting sidewalks)?\n",
    "Green building score?\n",
    "Air quality of city/neighborhood?\n",
    "Air quality of home (VOCs, materials)\n",
    "Curbside waster services?\n",
    "Curbside recycling services?\n",
    "Curbside composting services?\n",
    "Average heating/cooling costs?\n",
    "Is sustainable energy availalbe?\n",
    "Show me the impact of flight patterns\n",
    "What are the zoning breakdowns of this neighborhood? (section 8, residtential, mixed used, commercial, etc)?\n",
    "What is the estimated time to sell my home right now?\n",
    "How long does it take to sell a home in my neighborhood right now?\n",
    "How long does it take to sell a home on my street right now?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_mark(s):\n",
    "    return s[:-1] if s.endswith('?') or s.endswith('.') else s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ojo_sents = ojo_sents.split('\\n') # split into list of sent strings.\n",
    "ojo_sents = ojo_sents[1:len(ojo_sents)-1] # get rid of ''s in front and end.\n",
    "ojo_sents = list({drop_mark(sent) for sent in ojo_sents}) # get rid of question mark and duplicates.\n",
    "ojo_sents = [to_lemmas(sent) for sent in ojo_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1 = 'are the schools in the neighborhood good?'\n",
    "q2 = 'i care the most about the commute time between home and work.'\n",
    "q3 = 'is this a safe neighborhood?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_lemmas(s):\n",
    "    parsed_s = parser(unicode(s))\n",
    "    return [token.lemma_ for token in parsed_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_sim(q, k=5):\n",
    "    \n",
    "    q = to_lemmas(drop_mark(q))\n",
    "    sents = nlargest(k, ojo_sents, key=lambda s: overall_sent_sim(q,s))\n",
    "    \n",
    "    for i,sent in enumerate(sents):\n",
    "        print \"Sim Rank: %d | Sent: %s\" % (i+1,' '.join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim Rank: 1 | Sent: what be the quality of school in this neighborhood\n",
      "Sim Rank: 2 | Sent: what be the utility cost in this neighborhood\n",
      "Sim Rank: 3 | Sent: what be the crime statistic in this neighborhood\n",
      "Sim Rank: 4 | Sent: what be the walkability score in this neighborhood\n",
      "Sim Rank: 5 | Sent: what be the number of register sex offender in this neighborhood\n"
     ]
    }
   ],
   "source": [
    "most_sim(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim Rank: 1 | Sent: what be the best month to list a home like mine for the most money and short time\n",
      "Sim Rank: 2 | Sent: what be the estimate time to sell my home right now\n",
      "Sim Rank: 3 | Sent: i want a area where the home be setback from the streeet\n",
      "Sim Rank: 4 | Sent: what be the commute time for this neighborhood\n",
      "Sim Rank: 5 | Sent: show me the impact of flight pattern\n"
     ]
    }
   ],
   "source": [
    "most_sim(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim Rank: 1 | Sent: be this a pet friendly neighborhood\n",
      "Sim Rank: 2 | Sent: how bicycle friendly be this neighborhood\n",
      "Sim Rank: 3 | Sent: what be the utility cost in this neighborhood\n",
      "Sim Rank: 4 | Sent: what be the poverty score of this neighborhood\n",
      "Sim Rank: 5 | Sent: what be the number of register sex offender in this neighborhood\n"
     ]
    }
   ],
   "source": [
    "most_sim(q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim Rank: 1 | Sent: be this a pet friendly neighborhood\n",
      "Sim Rank: 2 | Sent: how bicycle friendly be this neighborhood\n",
      "Sim Rank: 3 | Sent: what be the utility cost in this neighborhood\n",
      "Sim Rank: 4 | Sent: what be the poverty score of this neighborhood\n",
      "Sim Rank: 5 | Sent: what be the crime statistic in this neighborhood\n"
     ]
    }
   ],
   "source": [
    "most_sim('is this neighborhood dangerous?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qq1 = 'the dog ate an apple'.split()\n",
    "qq2 = 'the apple ate a dog'.split()\n",
    "qq3 = 'the cat ate an apple'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78328571189411678"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_sent_sim(qq1,qq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89501360904995508"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_sent_sim(qq1,qq3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim Rank: 1 | Sent: what be the poverty score of this neighborhood\n",
      "Sim Rank: 2 | Sent: what be the walkability score in this neighborhood\n",
      "Sim Rank: 3 | Sent: be this a pet friendly neighborhood\n",
      "Sim Rank: 4 | Sent: be there complete street in this neighborhood ( connect sidewalk )\n",
      "Sim Rank: 5 | Sent: green build score\n"
     ]
    }
   ],
   "source": [
    "most_sim('are there murders here?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Extension: SRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from practnlptools.tools import Annotator\n",
    "from spacy.en import English\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "antr = Annotator()\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_root(ph):\n",
    "    \n",
    "    parsed_ph = parser(unicode(ph))\n",
    "    \n",
    "    return filter(lambda tk: tk.dep_=='ROOT', [tk for tk in parsed_ph])[0].lemma_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 ms, sys: 403 µs, total: 1.74 ms\n",
      "Wall time: 1.12 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'brother'"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_root('his brother , whom he call the witness ,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_argstruct(s_lm):\n",
    "    \n",
    "    srl = antr.getAnnotations(s_lm)['srl']\n",
    "    argstruct = defaultdict(dict)\n",
    "    for entry in srl:\n",
    "        v = entry['V']\n",
    "        for arg_lb,arg in entry.iteritems():\n",
    "            if arg_lb=='V': continue\n",
    "            if len(arg)>1: arg = get_root(arg)\n",
    "            if arg_lb not in set(['A0','A1','A2']):\n",
    "                argstruct[v]['OTHER'] = arg\n",
    "            else:\n",
    "                argstruct[v][arg_lb] = arg\n",
    "    \n",
    "    return argstruct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.63 ms, sys: 13 ms, total: 16.6 ms\n",
      "Wall time: 299 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'accuse': {'A0': u'amrozi', 'A1': u'brother', 'A2': u'distort'},\n",
       "             'call': {'A0': u'he', 'A1': u'witness', 'OTHER': u'whom'},\n",
       "             'distort': {'A0': u'brother',\n",
       "              'A1': u'evidence',\n",
       "              'OTHER': u'deliberately'}})"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_argstruct('amrozi accuse his brother , whom he call the witness , of deliberately distort his evidence .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def args_sim(arg_dic1, arg_dic2):\n",
    "    \n",
    "    nargs = len(set(arg_dic1.keys()+arg_dic2.keys()))\n",
    "    score = 0\n",
    "    for arg_lb in arg_dic1:\n",
    "        if arg_lb in arg_dic2.keys():\n",
    "            score += word_sim(arg_dic1[arg_lb],arg_dic2[arg_lb])\n",
    "    \n",
    "    return score / nargs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arg_dic1 = {'A0': 'amrozi', 'A1': 'brother', 'A2': 'distort'} # accuse\n",
    "arg_dic2 = {'A0': 'amrozi', 'A1': 'brother', 'A2': 'kill'} # the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62346247\n",
      "0.332111374038\n"
     ]
    }
   ],
   "source": [
    "print args_sim(arg_dic1,arg_dic1)\n",
    "print args_sim(arg_dic1,arg_dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def argstruct_sim(as1, as2):\n",
    "    \n",
    "    nvs = len(set(as1.keys()+as2.keys()))\n",
    "    if len(as1)==0 or len(as2)==0: return 0\n",
    "    score = 0\n",
    "    for v1 in as1.keys():\n",
    "        if v1 in as2.keys():\n",
    "            score += args_sim(as1[v1],as2[v1])\n",
    "        else:\n",
    "            v2 = nlargest(1, as2.keys(), key=lambda v2: word_sim(v1,v2))[0]\n",
    "            score += word_sim(v1,v2)*args_sim(as1[v1],as2[v2])\n",
    "    \n",
    "    return score / nvs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1, s2 = df_train.ix[0]['#1 String'], df_train.ix[0]['#2 String']\n",
    "s3 = df_train.ix[1]['#1 String']\n",
    "parsed_s1_lm = ' '.join([token.lemma_ for token in parser(s1)])\n",
    "parsed_s2_lm = ' '.join([token.lemma_ for token in parser(s2)])\n",
    "parsed_s3_lm = ' '.join([token.lemma_ for token in parser(s3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "argstruct_s1 = get_argstruct(parsed_s1_lm)\n",
    "argstruct_s2 = get_argstruct(parsed_s2_lm)\n",
    "argstruct_s3 = get_argstruct(parsed_s3_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'dict'>, {'call': {'A1': u'witness', 'A0': u'he', 'OTHER': u'whom'}, 'distort': {'A1': u'evidence', 'A0': u'brother', 'OTHER': u'deliberately'}, 'accuse': {'A1': u'brother', 'A0': u'amrozi', 'A2': u'distort'}})\n",
      "\n",
      "defaultdict(<type 'dict'>, {'distort': {'A1': u'evidence', 'A0': u'brother', 'OTHER': u'deliberately'}, 'accuse': {'A1': u'brother', 'A0': u'amrozi', 'OTHER': u'refer', 'A2': u'distort'}, 'refer': {'A1': u'to', 'A0': u'amrozi', 'A2': u'as'}})\n"
     ]
    }
   ],
   "source": [
    "print argstruct_s1; print\n",
    "print argstruct_s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28142923286288285"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argstruct_sim(argstruct_s1,argstruct_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0078325380278391928"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argstruct_sim(argstruct_s1,argstruct_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argsim_test1(idx):\n",
    "    as1 = get_argstruct(' '.join(X_train[idx]['s1_lm']).encode('utf8'))\n",
    "    as2 = get_argstruct(' '.join(X_train[idx]['s2_lm']).encode('utf8'))\n",
    "    sim = argstruct_sim(as1,as2)\n",
    "    label = Y_train[idx]\n",
    "    print 'idx = %d | argsim = %.6f | label = %s' % (idx,sim,label)\n",
    "    return sim, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argsim_test2(X,Y):\n",
    "    sims_0, sims_1 = [], []\n",
    "    sims, labels = [], []\n",
    "    for i,x in X.iteritems():\n",
    "        as1 = get_argstruct(' '.join(x['s1_lm']).encode('utf8'))\n",
    "        as2 = get_argstruct(' '.join(x['s2_lm']).encode('utf8'))\n",
    "        sim = argstruct_sim(as1, as2)\n",
    "        label = Y[i]\n",
    "        sims.append(sim)\n",
    "        labels.append(label)\n",
    "        if label==0:\n",
    "            sims_0.append(sim)\n",
    "        else:\n",
    "            sims_1.append(sim)\n",
    "        if i!=0 and i%100==0:\n",
    "            print \"[processed: %d] avg. 0 sim: %.6f | avg. 1 sim: %.6f\" % (i,np.mean(sims_0),np.mean(sims_1))\n",
    "    return sims, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sims, labels = [], []\n",
    "# for i in xrange(100):\n",
    "#     sim, label = argsim_test1(i)\n",
    "#     sims.append(sim)\n",
    "#     labels.append(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[processed: 100] avg. 0 sim: 0.087554 | avg. 1 sim: 0.194288\n",
      "[processed: 200] avg. 0 sim: 0.090766 | avg. 1 sim: 0.213298\n",
      "[processed: 300] avg. 0 sim: 0.102342 | avg. 1 sim: 0.222098\n",
      "[processed: 400] avg. 0 sim: 0.111044 | avg. 1 sim: 0.225719\n",
      "[processed: 500] avg. 0 sim: 0.110492 | avg. 1 sim: 0.235329\n",
      "[processed: 600] avg. 0 sim: 0.107436 | avg. 1 sim: 0.237669\n",
      "[processed: 700] avg. 0 sim: 0.105167 | avg. 1 sim: 0.237473\n",
      "[processed: 800] avg. 0 sim: 0.104041 | avg. 1 sim: 0.236566\n",
      "[processed: 900] avg. 0 sim: 0.103174 | avg. 1 sim: 0.233549\n",
      "[processed: 1000] avg. 0 sim: 0.105833 | avg. 1 sim: 0.235653\n",
      "[processed: 1100] avg. 0 sim: 0.116416 | avg. 1 sim: 0.236362\n",
      "[processed: 1200] avg. 0 sim: 0.112117 | avg. 1 sim: 0.233840\n",
      "[processed: 1300] avg. 0 sim: 0.119859 | avg. 1 sim: 0.230562\n",
      "[processed: 1400] avg. 0 sim: 0.121389 | avg. 1 sim: 0.234079\n",
      "[processed: 1500] avg. 0 sim: 0.120173 | avg. 1 sim: 0.233276\n",
      "[processed: 1600] avg. 0 sim: 0.118393 | avg. 1 sim: 0.234271\n",
      "[processed: 1700] avg. 0 sim: 0.116467 | avg. 1 sim: 0.237896\n",
      "[processed: 1800] avg. 0 sim: 0.119959 | avg. 1 sim: 0.237833\n",
      "[processed: 1900] avg. 0 sim: 0.119106 | avg. 1 sim: 0.237977\n",
      "[processed: 2000] avg. 0 sim: 0.122005 | avg. 1 sim: 0.238429\n",
      "[processed: 2100] avg. 0 sim: 0.121331 | avg. 1 sim: 0.236412\n",
      "[processed: 2200] avg. 0 sim: 0.119992 | avg. 1 sim: 0.236050\n",
      "[processed: 2300] avg. 0 sim: 0.118698 | avg. 1 sim: 0.235402\n",
      "[processed: 2400] avg. 0 sim: 0.118937 | avg. 1 sim: 0.235649\n",
      "[processed: 2500] avg. 0 sim: 0.119346 | avg. 1 sim: 0.234313\n",
      "[processed: 2600] avg. 0 sim: 0.118815 | avg. 1 sim: 0.234660\n",
      "[processed: 2700] avg. 0 sim: 0.119568 | avg. 1 sim: 0.232696\n",
      "[processed: 2800] avg. 0 sim: 0.120089 | avg. 1 sim: 0.234885\n",
      "[processed: 2900] avg. 0 sim: 0.120749 | avg. 1 sim: 0.234601\n",
      "[processed: 3000] avg. 0 sim: 0.120271 | avg. 1 sim: 0.233706\n",
      "[processed: 3100] avg. 0 sim: 0.120116 | avg. 1 sim: 0.232634\n",
      "[processed: 3200] avg. 0 sim: 0.120232 | avg. 1 sim: 0.233128\n",
      "[processed: 3300] avg. 0 sim: 0.120943 | avg. 1 sim: 0.233198\n",
      "[processed: 3400] avg. 0 sim: 0.120320 | avg. 1 sim: 0.233861\n",
      "[processed: 3500] avg. 0 sim: 0.120462 | avg. 1 sim: 0.232941\n",
      "[processed: 3600] avg. 0 sim: 0.121904 | avg. 1 sim: 0.231146\n",
      "[processed: 3700] avg. 0 sim: 0.122143 | avg. 1 sim: 0.231899\n",
      "[processed: 3800] avg. 0 sim: 0.122730 | avg. 1 sim: 0.231450\n",
      "[processed: 3900] avg. 0 sim: 0.121485 | avg. 1 sim: 0.230471\n",
      "[processed: 4000] avg. 0 sim: 0.122664 | avg. 1 sim: 0.231923\n",
      "CPU times: user 23.3 s, sys: 45.9 s, total: 1min 9s\n",
      "Wall time: 39min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sims, labels = argsim_test2(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[processed: 100] avg. 0 sim: 0.094453 | avg. 1 sim: 0.184534\n",
      "[processed: 200] avg. 0 sim: 0.109066 | avg. 1 sim: 0.212809\n",
      "[processed: 300] avg. 0 sim: 0.106324 | avg. 1 sim: 0.215218\n",
      "[processed: 400] avg. 0 sim: 0.104338 | avg. 1 sim: 0.224117\n",
      "[processed: 500] avg. 0 sim: 0.109962 | avg. 1 sim: 0.221442\n",
      "[processed: 600] avg. 0 sim: 0.117865 | avg. 1 sim: 0.224665\n",
      "[processed: 700] avg. 0 sim: 0.126886 | avg. 1 sim: 0.232550\n",
      "[processed: 800] avg. 0 sim: 0.125812 | avg. 1 sim: 0.235065\n",
      "[processed: 900] avg. 0 sim: 0.126797 | avg. 1 sim: 0.235669\n",
      "[processed: 1000] avg. 0 sim: 0.122362 | avg. 1 sim: 0.236606\n",
      "[processed: 1100] avg. 0 sim: 0.123071 | avg. 1 sim: 0.238742\n",
      "[processed: 1200] avg. 0 sim: 0.126195 | avg. 1 sim: 0.239168\n",
      "[processed: 1300] avg. 0 sim: 0.126372 | avg. 1 sim: 0.237842\n",
      "[processed: 1400] avg. 0 sim: 0.127697 | avg. 1 sim: 0.235775\n",
      "[processed: 1500] avg. 0 sim: 0.123811 | avg. 1 sim: 0.237493\n",
      "[processed: 1600] avg. 0 sim: 0.124741 | avg. 1 sim: 0.235304\n",
      "[processed: 1700] avg. 0 sim: 0.123377 | avg. 1 sim: 0.234652\n",
      "CPU times: user 15.3 s, sys: 25.2 s, total: 40.6 s\n",
      "Wall time: 20min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sims_test, labels_test = argsim_test2(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONVERT TO LISTS OF LISTS\n",
    "sims = [[sim] for sim in sims]\n",
    "sims_test = [[sim] for sim in sims_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAVE\n",
    "# with open(data_path+'srl_sim.p','wb') as f:\n",
    "#     cPickle.dump((sims,labels,sims_test,labels_test), f)\n",
    "# LOAD \n",
    "# with open(data_path+'srl_sim.p','rb') as f:\n",
    "#     sims,labels,sims_test,labels_test = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eval 1: Pearson's Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pearson: 0.227632 (p = 0.000000)\n",
      "test pearson: 0.234784 (p = 0.000000)\n"
     ]
    }
   ],
   "source": [
    "print \"train pearson: %.6f (p = %.6f)\" % pearsonr([sim for [sim] in sims],labels) \n",
    "print \"test pearson: %.6f (p = %.6f)\" % pearsonr([sim for [sim] in sims_test],labels_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eval 2: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_srl = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_srl.fit(sims,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.675417\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      1323\n",
      "          1       0.68      1.00      0.81      2753\n",
      "\n",
      "avg / total       0.46      0.68      0.54      4076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(sims, labels, lr_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.664928\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       578\n",
      "          1       0.66      1.00      0.80      1147\n",
      "\n",
      "avg / total       0.44      0.66      0.53      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(sims_test, labels_test, lr_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_srl = svm.SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_srl.fit(sims, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.675417\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      1323\n",
      "          1       0.68      1.00      0.81      2753\n",
      "\n",
      "avg / total       0.46      0.68      0.54      4076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(sims, labels, svc_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.664928\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       578\n",
      "          1       0.66      1.00      0.80      1147\n",
      "\n",
      "avg / total       0.44      0.66      0.53      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(sims_test, labels_test, svc_srl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eval 3: OJO Sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_sim_srl(q, k=5):\n",
    "    \n",
    "    q = ' '.join(to_lemmas(drop_mark(q)))\n",
    "    sents = nlargest(k, ojo_sents, key=lambda s: argstruct_sim(get_argstruct(q),get_argstruct(' '.join(s))))\n",
    "    \n",
    "    for i,sent in enumerate(sents):\n",
    "        print \"Sim Rank: %d | Sent: %s\" % (i+1,sent)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim Rank: 1 | Sent: [u'show', u'me', u'the', u'impact', u'of', u'flight', u'pattern']\n",
      "Sim Rank: 2 | Sent: [u'what', u'be', u'the', u'average', u'demographic', u'of', u'this', u'neighborhood', u'?']\n",
      "Sim Rank: 3 | Sent: [u'what', u'be', u'the', u'estimate', u'time', u'to', u'sell', u'my', u'home', u'right', u'now']\n",
      "Sim Rank: 4 | Sent: [u'what', u'confidence', u'level', u'do', u'ojo', u'have', u'that', u'i', u'should', u'list', u'my', u'home', u'now']\n",
      "Sim Rank: 5 | Sent: [u'how', u'fast', u'will', u'my', u'home', u'sell']\n",
      "CPU times: user 118 ms, sys: 716 ms, total: 834 ms\n",
      "Wall time: 34.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "most_sim_srl(q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eval 4: Wan + Li + ArgSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "argsims = (sims, labels, sims_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize_plusplus(wan_fts, li_fts, argsims):\n",
    "    \n",
    "    X_train_wan, Y_train_wan, X_test_wan, Y_test_wan = wan_fts\n",
    "    X_train_li, Y_train_li, X_test_li, Y_test_li = li_fts\n",
    "    X_train_argsim, Y_train_argsim, X_test_argsim, Y_test_argsim = argsims\n",
    "    \n",
    "    X_train_fts, Y_train_fts = [], []\n",
    "    X_test_fts, Y_test_fts = [], []\n",
    "    \n",
    "    for i,(x_wan,x_li,x_argsim) in enumerate(zip(X_train_wan,X_train_li,X_train_argsim)):\n",
    "        X_train_fts.append(x_wan+x_li+x_argsim) \n",
    "        Y_train_fts.append(Y_train_li[i])\n",
    "    for i,(x_wan,x_li,x_argsim) in enumerate(zip(X_test_wan,X_test_li,X_test_argsim)):\n",
    "        X_test_fts.append(x_wan+x_li+x_argsim)\n",
    "        Y_test_fts.append(Y_test_li[i])\n",
    "        \n",
    "    return X_train_fts, Y_train_fts, X_test_fts, Y_test_fts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_fts, Y_train_fts, X_test_fts, Y_test_fts = featurize_plusplus(wan_fts, li_fts, argsims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_all = LogisticRegression()\n",
    "lr_all.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.751227\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.50      0.56      1323\n",
      "          1       0.78      0.87      0.83      2753\n",
      "\n",
      "avg / total       0.74      0.75      0.74      4076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_train_fts, Y_train_fts, lr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.729275\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.50      0.55       578\n",
      "          1       0.77      0.84      0.81      1147\n",
      "\n",
      "avg / total       0.72      0.73      0.72      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_test_fts, Y_test_fts, lr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_linear_all = svm.SVC(kernel='linear')\n",
    "svm_rbf_all = svm.SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 19.5 ms, total: 12.5 s\n",
      "Wall time: 12.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_linear_all.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.735072\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.47      0.55       578\n",
      "          1       0.77      0.87      0.81      1147\n",
      "\n",
      "avg / total       0.72      0.74      0.72      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_test_fts, Y_test_fts, svm_linear_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 13.8 ms, total: 1.07 s\n",
      "Wall time: 1.06 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_rbf_all.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.695072\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.31      0.40       578\n",
      "          1       0.72      0.89      0.80      1147\n",
      "\n",
      "avg / total       0.67      0.70      0.66      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_test_fts, Y_test_fts, svm_rbf_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
