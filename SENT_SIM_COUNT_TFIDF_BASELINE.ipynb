{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Similarity Measures I: Count, TFIDF Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Contents\n",
    "\n",
    "* I. Corpora\n",
    "* II. Baseline\n",
    "    * Word Overlap (Naive Overlap; Word-Discriminativeness-Based Overlap)\n",
    "    * TF-IDF Overlap\n",
    "* III. Relative-Frequency Measure\n",
    "* IV. Probabilistic Model\n",
    "* V. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. MSR Paraphrase Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/CORPORA/paraphrase/msr_paraphrase_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿Sentence ID</th>\n",
       "      <th>String</th>\n",
       "      <th>Author</th>\n",
       "      <th>URL</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Date</th>\n",
       "      <th>Web Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>702876</td>\n",
       "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
       "      <td>Darren Goodsir</td>\n",
       "      <td>www.theage.com.au</td>\n",
       "      <td>*</td>\n",
       "      <td>June 5 2003</td>\n",
       "      <td>2003/06/04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>702977</td>\n",
       "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
       "      <td>Darren Goodsir</td>\n",
       "      <td>www.smh.com.au</td>\n",
       "      <td>Sydney Morning Herald</td>\n",
       "      <td>June 5 2003</td>\n",
       "      <td>2003/06/04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2108705</td>\n",
       "      <td>Yucaipa owned Dominick's before selling the ch...</td>\n",
       "      <td>MICHAEL GIBBS</td>\n",
       "      <td>www.nwherald.com</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>2003/08/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2108831</td>\n",
       "      <td>Yucaipa bought Dominick's in 1995 for $693 mil...</td>\n",
       "      <td>ALEX VEIGA</td>\n",
       "      <td>www.miami.com</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>2003/08/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330381</td>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>Philip Pangalos</td>\n",
       "      <td>www.alertnet.org</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>2003/06/25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿Sentence ID                                             String  \\\n",
       "0        702876  Amrozi accused his brother, whom he called \"th...   \n",
       "1        702977  Referring to him as only \"the witness\", Amrozi...   \n",
       "2       2108705  Yucaipa owned Dominick's before selling the ch...   \n",
       "3       2108831  Yucaipa bought Dominick's in 1995 for $693 mil...   \n",
       "4       1330381  They had published an advertisement on the Int...   \n",
       "\n",
       "            Author                URL                 Agency         Date  \\\n",
       "0   Darren Goodsir  www.theage.com.au                      *  June 5 2003   \n",
       "1   Darren Goodsir     www.smh.com.au  Sydney Morning Herald  June 5 2003   \n",
       "2    MICHAEL GIBBS   www.nwherald.com                      *            *   \n",
       "3       ALEX VEIGA      www.miami.com                      *            *   \n",
       "4  Philip Pangalos   www.alertnet.org                      *            *   \n",
       "\n",
       "     Web Date  \n",
       "0  2003/06/04  \n",
       "1  2003/06/04  \n",
       "2  2003/08/23  \n",
       "3  2003/08/23  \n",
       "4  2003/06/25  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path, delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10594"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['String'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = list(df['String'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\n",
      "\n",
      "Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\n",
      "\n",
      "Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.\n",
      "\n",
      "Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.\n",
      "\n",
      "They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(5):\n",
    "    print data[i]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_msr():\n",
    "    \n",
    "    parsed_sents = [parser(unicode(sent.decode('utf8','ignore'))) for sent in data]\n",
    "    lemma_sents = [[token.lemma_ for token in parsed_sent] \n",
    "                   for parsed_sent in parsed_sents]\n",
    "    \n",
    "    return lemma_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.9 s, sys: 156 ms, total: 19 s\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sents = parse_msr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'amrozi', u'accuse', u'his', u'brother', u',', u'whom', u'he', u'call', u'\"', u'the', u'witness', u'\"', u',', u'of', u'deliberately', u'distort', u'his', u'evidence', u'.']\n",
      "\n",
      "[u'refer', u'to', u'him', u'as', u'only', u'\"', u'the', u'witness', u'\"', u',', u'amrozi', u'accuse', u'his', u'brother', u'of', u'deliberately', u'distort', u'his', u'evidence', u'.']\n",
      "\n",
      "[u'yucaipa', u'own', u'dominick', u\"'s\", u'before', u'sell', u'the', u'chain', u'to', u'safeway', u'in', u'1998', u'for', u'$', u'2.5', u'billion', u'.']\n",
      "\n",
      "[u'yucaipa', u'buy', u'dominick', u\"'s\", u'in', u'1995', u'for', u'$', u'693', u'million', u'and', u'sell', u'it', u'to', u'safeway', u'for', u'$', u'1.8', u'billion', u'in', u'1998', u'.']\n",
      "\n",
      "[u'they', u'have', u'publish', u'an', u'advertisement', u'on', u'the', u'internet', u'on', u'june', u'10', u',', u'offer', u'the', u'cargo', u'for', u'sale', u',', u'he', u'add', u'.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(5):\n",
    "    print sents[i]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**:\n",
    "\n",
    "* $q, r$: *query sentence* and *candidate sentence* respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Word Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* **Variant I**: \n",
    "    * Equation: $SIM(q,r) = \\frac{|q|\\cap|r|}{|q|}$ (cf. Metzler et al. (2005):3)\n",
    "\n",
    "* **Variant II**: \n",
    "    * Equation: $SIM(q,r) = \\frac{|q|\\cap|r|}{|q|}\\left(\\sum_{w\\in q\\cap r}log\\frac{N}{df_w}\\right)$ (cf. ibid.)\n",
    "    * Notation: $N$: total number of documents; $df_w$: document frequency of word $w$.\n",
    "    * Idea: \"... high IDF terms are typically stronger indicators of shared heritage between two sentences than are low IDF terms\" (cf. ibid.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_overlap1(q, r):\n",
    "    \n",
    "    return len(set(q).intersection(set(r))) / len(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = sents[0]\n",
    "r1 = sents[1] # known to be the paraphrase of q\n",
    "r2 = sents[2] # known to not be the paraphrase of q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684210526316\n",
      "0.105263157895\n",
      "CPU times: user 156 µs, sys: 78 µs, total: 234 µs\n",
      "Wall time: 179 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print word_overlap1(q,r1)\n",
    "print word_overlap1(q,r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log = lambda x: np.log(x) if x>0 else 0\n",
    "    # intuitively N > word_count(w) for any w,\n",
    "    #  therefore we cannot let idf(w) be negative\n",
    "    #  even when word_count(w) = 0 for w.\n",
    "div = lambda x,y: x/y if y!=0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_w = lambda w: sum(1 if w in sent else 0 for sent in sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_overlap2(q, r):\n",
    "    \n",
    "    w_list = list(set(q).union(set(r)))\n",
    "    N = len(sents)\n",
    "    \n",
    "    return word_overlap1(q, r) * sum(log(div(N,df_w(w))) for w in w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.7708837465\n",
      "14.0312695745\n",
      "CPU times: user 344 ms, sys: 45.5 ms, total: 390 ms\n",
      "Wall time: 357 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print word_overlap2(q,r1)\n",
    "print word_overlap2(q,r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. TF-IDF Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* **Allan et al. (2003)'s TF-IDF**\n",
    "    * Equation: $SIM(q,r) = \\sum_{w\\in q\\cap r} log(tf_{w,q} + 1)log(tf_{w,r} + 1)log\\left(\\frac{N+1}{df_w+0.5}\\right)$ (cf. Metzler et al. (2005):3)\n",
    "    * Notation: $tf_{w,q}, tf_{w,r}$: the number of times term $w$ appears in $q,r$ respectively. the rest are the same as before.\n",
    "    * Idea: \"... the more frequently a word appears in a passage, the more indicative that word is of the topicality of that passage; and that the less frequently a term appears in a collection, the greater its power to discriminate between interesting and uninteresting passages.\" (cf. ibid.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf = lambda w,s: s.count(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf(q, r):\n",
    "    \n",
    "    w_list = list(set(q).union(set(r)))\n",
    "    N = len(sents)\n",
    "    \n",
    "    return sum(log(tf(w,q)+1)*log(tf(w,r)+1)*log(div(N+1,df_w(w)+.5)) \n",
    "               for w in w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.3208219916\n",
      "0.162544003972\n",
      "CPU times: user 363 ms, sys: 41.3 ms, total: 405 ms\n",
      "Wall time: 379 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print tf_idf(q,r1)\n",
    "print tf_idf(q,r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Relative-Frequency Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* **Hoad & Zobel (2003)'s RF**\n",
    "    * Equation: $SIM(q,r) = \\frac{1}{1+\\frac{max(|q|,|r|)}{min(|q|,|r|)}}\\sum_{w\\in q\\cap r}\\frac{logN/df_w}{1+|tf_{w,q}-tf_{w,r}|}$ (cf. Metzler et al. (2005):4)\n",
    "    * Idea: \n",
    "        * Discriminator: $log\\frac{N}{df_w}$ (i.e. TF-IDF)\n",
    "        * Penalizer 1: $\\frac{max(|q|,|r|)}{min(|q|,|r|)}$, penalizes differences in the overall lengths of the sentences.\n",
    "        * Penalizer 2: $|tf_{w,q}-tf_{w,r}|$, penalizes inequalities in the relative frequency of a word between the two sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf(q, r):\n",
    "    \n",
    "    w_list = list(set(q).union(set(r)))\n",
    "    N = len(sents)\n",
    "    \n",
    "    return 1/(1+div(max(len(q),len(r)),min(len(q),len(r)))) * \\\n",
    "           sum(div(log(N/df_w(w)),1+(tf(w,q)-tf(w,r))) for w in w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.8548071877\n",
      "14.670872733\n",
      "CPU times: user 373 ms, sys: 43.8 ms, total: 417 ms\n",
      "Wall time: 388 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print rf(q,r1)\n",
    "print rf(q,r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Probabilistic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* **Metzler et al.'s Statistical Translation Based Similarity**\n",
    "    * Equation: $SIM(q,r) = \\prod_{i=1}^{|q|}\\frac{tf_{q_i,r}+\\mu\\cdot p(q_i|C)}{|r| + \\mu}$ (cf. Metzler et al. (2005):4)\n",
    "    * Notation: $\\mu$: the number of translate-to-null nodes in an alignment (cf. IBM Translation Model 1); $C$: background model for term (conditional) frequencies inferred from corpus.\n",
    "    * Assumptions: \n",
    "        * The candidate sentence $r$'s possible alignments to the query sentence $q$ are uniformly distributed.\n",
    "        * The probability that $r$ translates into a sentence of length $\\mathcal{l}$ is uniformly distributed.\n",
    "        * In the absence of any other evidence, an unalgined word is likely to be present in a sentence with a probability equal to its overall probability in the more generalized background language model. (i.e. $p_t(q_i|r_j) = p(q_i|C)$).\n",
    "        * Each word translates to itself (i.e. $p_t(q_i|r_j)=1$ if $q_i=r_j$).\n",
    "    * Hyperparameter:\n",
    "        * $\\mu$: the closer $\\mu$ is to $0$, the closer the model is to a *word overlap* type of measure (good at finding exact matches), on the other end of the spectrum, the model will be finding *topically relevant matches*. $\\mu = 1$ and $\\mu = 2500$ are explored. (cf. ibid.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_w_count = sum(1 for sent in sents for w in sent)\n",
    "p_qi_C = lambda q_i: div(sum(sent.count(q_i) for sent in sents),total_w_count)  # C = sents, our corpus.\n",
    "prod = lambda l: reduce(mul, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stat_trans_sim(q, r, mu=1):\n",
    "    \n",
    "    return prod(div(tf(q[i],r)+mu*p_qi_C(q[i]),len(r)+mu)\n",
    "                for i in xrange(len(q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.92226629921e-34\n",
      "1.91231846503e-76\n",
      "\n",
      "2.82427653851e-49\n",
      "2.53971502954e-55\n",
      "CPU times: user 565 ms, sys: 22.9 ms, total: 587 ms\n",
      "Wall time: 574 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print stat_trans_sim(q,r1)\n",
    "print stat_trans_sim(q,r2)\n",
    "print\n",
    "print stat_trans_sim(q,r1,2500)\n",
    "print stat_trans_sim(q,r2,2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method**\n",
    "\n",
    "* With the 5297 pairs of paraphrases from MSR Paraphrase Corpus, define a *correct classification* for inputting a sentence $q$ to be retrieving its pairmate as the candidate sentence that has the highest similarity score.\n",
    "* Due to constraint on computational cost, I sample 100 $q$s and then 10 $r$s for the evaluation. For each $q$, I first compute its similarity to its pairmate (i.e. its true paraphrase), and then iterate through the sampled $r$s. If $q$'s similarity to its pairmate is the max in iterations, I count 1 correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s2i = {' '.join(s):i for i,s in enumerate(sents)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s2s = {i:i+1 for i in xrange(0,len(sents),2)}\n",
    "s22s1 = {j:i for i,j in s2s.iteritems()}\n",
    "s2s.update(s22s1) # a dictionary the value idx of a key idx is the key's pairmate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "without = lambda i,size: range(0,i)+range(i+1,size) # return the list of indices that don't include i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(sim, sample_num, base_num): \n",
    "    # sample_num: evaluation size.\n",
    "    # base_num: size of sents to measure sim with.\n",
    "    \n",
    "    print \"... sample size: %d | base size: %d\" % (sample_num,base_num)\n",
    "    sample_idxs = random.sample(range(len(sents)),sample_num)\n",
    "    \n",
    "    correct = 0\n",
    "    for i in sample_idxs:\n",
    "        true_sim = sim(sents[i],sents[s2s[i]]) # sent's similarity to its pairmate.\n",
    "        base_idxs = random.sample(without(i,len(sents)),base_num)\n",
    "        fail = False\n",
    "        for j in base_idxs: \n",
    "            if i!=j and sim(sents[i],sents[j])>true_sim:\n",
    "                fail = True\n",
    "                break \n",
    "        correct += 0 if fail else 1    \n",
    "    \n",
    "    print \"Accuracy: %.6f%%\" % ((correct/sample_num)*100)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... sample size: 100 | base size: 10\n",
      "Accuracy: 52.000000%\n",
      "CPU times: user 24.1 ms, sys: 2.07 ms, total: 26.1 ms\n",
      "Wall time: 24.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate(word_overlap1,sample_num=100,base_num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... sample size: 100 | base size: 10\n",
      "Accuracy: 46.000000%\n",
      "CPU times: user 2min 42s, sys: 1.28 s, total: 2min 43s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate(word_overlap2,sample_num=100,base_num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... sample size: 100 | base size: 10\n",
      "Accuracy: 52.000000%\n",
      "CPU times: user 2min 54s, sys: 1.3 s, total: 2min 55s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate(tf_idf,sample_num=100,base_num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... sample size: 100 | base size: 10\n",
      "Accuracy: 54.000000%\n",
      "CPU times: user 3min, sys: 1.62 s, total: 3min 2s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate(rf,sample_num=100,base_num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... sample size: 100 | base size: 10\n",
      "Accuracy: 52.000000%\n",
      "CPU times: user 2min 11s, sys: 972 ms, total: 2min 12s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate(stat_trans_sim,sample_num=100,base_num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
